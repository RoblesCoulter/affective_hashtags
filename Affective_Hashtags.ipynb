{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nnp_pl = pd.read_csv(\"playlist.csv\", names=[\"playlist_id\",\"track_id\",\"playlist_name\"])\\nnp_pl_json = json.loads(np_pl.to_json(orient=\"records\"))\\ndb.playlist.drop()\\ndb.playlist.insert_many(np_pl_json)\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## NowPlaying Cultural Sentiment Data\n",
    "\"\"\"\n",
    "cs_header = [\"hashtag\", \"AFINN_min\", \"AFINN_max\", \"AFINN_sum\", \"AFINN_avg\", \"OpinionLex_min\", \"OpinionLex_max\", \"OpinionLex_sum\", \"OpinionLex_avg\", \"Sentistrength_min\", \"Sentistrength_max\", \"Sentistrength_sum\", \"Sentistrength_avg\", \"Vader_min\", \"Vader_max\", \"Vader_sum\", \"Vader_avg\", \"SentimentHashtag_min\", \"SentimentHashtag_max\", \"SentimentHashtag_sum\", \"SentimentHashtag_avg\"]\n",
    "np_cs = pd.read_csv('np_cultural_sentiment.csv',names = cs_header)\n",
    "\"\"\"\n",
    "#IMPORTING Cultural Sentiment Data to MongoDB\n",
    "\"\"\"\n",
    "np_cs_json = json.loads(np_cs.to_json(orient=\"records\"))\n",
    "db.cultural_sentiment.drop()\n",
    "db.cultural_sentiment.insert_many(np_cs_json)\n",
    "\"\"\"\n",
    "## Transformation of NowPlaying Cultural Tweets to DataframeStructure\n",
    "\"\"\"\n",
    "output = []\n",
    "with open(\"np_cultural.json\") as f:\n",
    "    for line in f:     \n",
    "        output.append(json.load|s(line))\n",
    "np_c = pd.DataFrame(output)\n",
    "\"\"\"\n",
    "#IMPORTING Cultural Tweets to MongoDB\n",
    "\"\"\"\n",
    "db.cultural_tweet.drop()\n",
    "records = json.loads(np_c.T.to_json()).values()\n",
    "db.cultural_tweet.insert_many(records)\n",
    "\"\"\"\n",
    "\n",
    "## Transformation and Importing of Playlist Data from NowPlaying to MongoDB\n",
    "\"\"\"\n",
    "np_pl = pd.read_csv(\"playlist.csv\", names=[\"playlist_id\",\"track_id\",\"playlist_name\"])\n",
    "np_pl_json = json.loads(np_pl.to_json(orient=\"records\"))\n",
    "db.playlist.drop()\n",
    "db.playlist.insert_many(np_pl_json)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CULTURAL #NOWPLAYING DATA\n",
    "*********************************\n",
    "\n",
    "This dataset contains data describing the listening events of users (extracted from the #nowplaying dataset), the emotion extracted from the hashtags used in the according tweets and information about the location of the user.\n",
    "\n",
    "\n",
    "TWITTER AND TRACK DATA\n",
    "-------------------------------\n",
    "The data regarding the listening events is contained in np_cultural.zip and is encoded as json. It holds the following information:\n",
    "\n",
    "- id: the id of the underlying tweet [*]\n",
    "- user_id: the id of the user who sent the tweet (MD5 of it)\n",
    "- user_lang: The BCP 47 code for the user’s self-declared user interface language. [*]\n",
    "- user_time_zone: [*]\n",
    "- text: actual content of the tweet [*]\n",
    "- tweet_lang: language of the tweet (as detected by Twitter; BCP 47 language identifier corresponding to the machine-detected language of the Tweet text, or und if no language could be detected.) [*]\n",
    "- geo: Deprecated version of coordinates (however, we deal with data stemming from before this API change, therefore we still include it; cf. coordinates for a description)\n",
    "- coordinates: Represents the geographic location of this Tweet as reported by the user or client application. The inner coordinates array is formatted as geoJSON (longitude first, then latitude). [*]\n",
    "- place: When present, indicates that the tweet is associated (but not necessarily originating from) a Place. [*]\n",
    "- created_at: time the tweet was sent. [*]\n",
    "- source: Utility used to post the Tweet, as an HTML-formatted string. [*]\n",
    "- track_title: title of the track the user tweeted about\n",
    "- track_id: the unique id of the track (from #nowplaying dataset) \n",
    "- artist_name: name of artist performing the track\n",
    "- artist_id: the unique id of the artist (from #nowplaying dataset) \n",
    "- hashtags: list of hashtags used in the tweet.\n",
    "\n",
    "[*] for further information about the information gathered from Twitter, please consult https://dev.twitter.com/overview/api/tweets\n",
    "\n",
    "Please note that we do only add key-value pairs for geo/coordinates/place information if this information was provided by the Twitter API (i.e., missing keys signal that this information is not available for the given tweet).\n",
    "\n",
    "\n",
    "SENTIMENT DATA\n",
    "-------------------------------\n",
    "The data regarding the hashtag's sentiment (if any could be obtained) is contained in np_cultural_sentiment.csv and is formatted as csv. The sentiment score was obtained by applying a set of well-known sentiment dictionaries. The sentiment scores are scaled between 0 and 1 (very negative to very positive). For each dictionary, we list the minimum, maximum, sum and average sentiment score across all hashtags used within every tweet (most tweets only feature a single hashtag we can assign a sentiment value to)\n",
    "It contains the following information (in this particular order):\n",
    "- name of the hashtag\n",
    "- AFINN dictionary (min, max, sum, avg)\n",
    "- Opinion Lexicon (min, max, sum, avg)\n",
    "- Sentistrength Lexicon (min, max, sum, avg)\n",
    "- Vader (min, max, sum, avg)\n",
    "- Sentiment Hashtag Lexicon (min, max, sum, avg)\n",
    "\n",
    "\n",
    "Please note that we only added hashtags for which we could obtain a sentiment value from at least one sentiment dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import json\n",
    "import csv\n",
    "import pprint\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "from difflib import SequenceMatcher\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Call Mongo Instance\n",
    "client = MongoClient()\n",
    "db = client.now_playing\n",
    "\n",
    "#Spotify Instance\n",
    "client_credentials_manager = SpotifyClientCredentials(client_id=\"7736d10450e04c5f9e302bb07a4f6cf7\", client_secret=\"a11e29bc5c324ddeb19fc6249d303814\",)\n",
    "sp = spotipy.Spotify(client_credentials_manager = client_credentials_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the MusicBrainz Mapping of artists and tracks and tracks from cultural dataset\n",
    "\n",
    "`mongoimport -d now_playing -c mb_tracks --type csv --file mb_tracks.csv --fields \"np_id,mb_track_id\"`\n",
    "\n",
    "`mongoimport -d now_playing -c mb_artists --type csv --file mb_artists.csv --fields \"np_id,mb_artist_id\"`\n",
    "\n",
    "`mongoimport -d now_playing -c np_cultural_mb_tracks --type csv --file np_cultural_mb_tracks.csv --headerline\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_ids = db.cultural_tweet.distinct(\"user_id\")\n",
    "type(user_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of Tweets: 564301\n",
      "Total number of Songs: 39776\n",
      "Total number of Users: 9431\n",
      "Total number of Tweets with duration: 61013\n"
     ]
    }
   ],
   "source": [
    "#db.cultural_tweet.find({\"hashtag\": \"nobeats\"})\n",
    "user_tweets = db.cultural_tweet.find({\"user_id\": '1c10f9788fdcc4baf6cf6a2631fe78bc12102418'})\n",
    "#TOTAL Number of Tweets\n",
    "print(\"Total number of Tweets: \"+ str(db.cultural_tweet.find({}).count()))\n",
    "print(\"Total number of Songs: \" + str(len(db.cultural_tweet.distinct(\"track_title\"))))\n",
    "#Get Distinct User Ids\n",
    "print(\"Total number of Users: \" + str(len(user_ids)))\n",
    "print(\"Total number of Tweets with duration: \"+ str(db.cultural_tweet.find({\"duration_ms\" : {\"$exists\": True}}).count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "first = user_ids[0]\n",
    "user_songs = db.cultural_tweet.find({\"user_id\": first})\n",
    "initial_song = user_songs[0]\n",
    "initial_date = initial_song[\"created_at\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51045\n",
      "39776\n"
     ]
    }
   ],
   "source": [
    "#db.mb_tracks.find({\"np_id\": initial_song[\"track_id\"]}).count()\n",
    "#for song in user_songs:\n",
    "#    print(str(song[\"track_title\"]))\n",
    "#    print(str(song[\"track_id\"]))\n",
    "    \n",
    "print(len(db.cultural_tweet.distinct(\"track_id\")))\n",
    "print(len(db.cultural_tweet.distinct(\"track_title\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def similar(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()\n",
    "def convertMillis(millis):\n",
    "     seconds = (millis/1000)%60\n",
    "     minutes = (millis/(1000*60))%60\n",
    "     return str(int(minutes)) + \":\" +str(int(seconds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nsearch_query = initial_song[\"track_title\"].lower() +\" \"+ initial_song[\"artist_name\"].lower()\\nresults = sp.search(q=search_query,limit=5)\\nprint(\"Looking for: \"+search_query)\\nprint(\"Querying...\")\\nfor track in results[\"tracks\"][\"items\"]:\\n    artist_names = list(map(lambda x: x[\"name\"],track[\"artists\"]))\\n    print(\" \".join(artist_names))\\n    print(\"Found: \" + str(track[\"name\"]) + \" \"+str(track[\"artists\"][0][\"name\"]))\\n    print(convertMillis(track[\"duration_ms\"]))\\n    result_matcher = track[\"name\"].lower() + \" \" + track[\"artists\"][0][\"name\"].lower()\\n    print(\"Similarity Score: \" + str((similar(search_query, result_matcher))))\\n'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "search_query = initial_song[\"track_title\"].lower() +\" \"+ initial_song[\"artist_name\"].lower()\n",
    "results = sp.search(q=search_query,limit=5)\n",
    "print(\"Looking for: \"+search_query)\n",
    "print(\"Querying...\")\n",
    "for track in results[\"tracks\"][\"items\"]:\n",
    "    artist_names = list(map(lambda x: x[\"name\"],track[\"artists\"]))\n",
    "    print(\" \".join(artist_names))\n",
    "    print(\"Found: \" + str(track[\"name\"]) + \" \"+str(track[\"artists\"][0][\"name\"]))\n",
    "    print(convertMillis(track[\"duration_ms\"]))\n",
    "    result_matcher = track[\"name\"].lower() + \" \" + track[\"artists\"][0][\"name\"].lower()\n",
    "    print(\"Similarity Score: \" + str((similar(search_query, result_matcher))))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found intuition jewel\n",
      "Similarity Score: 1.0\n",
      "Found jesus queen\n",
      "Similarity Score: 1.0\n",
      "Found deus the sugarcubes\n",
      "Similarity Score: 1.0\n",
      "Found gangsta kat dahlia\n",
      "Similarity Score: 1.0\n",
      "Found symbolic death\n",
      "Similarity Score: 1.0\n",
      "Found as stevie wonder\n",
      "Similarity Score: 1.0\n",
      "Found scala agoria\n",
      "Similarity Score: 1.0\n",
      "Found you are my sunshine james last\n",
      "Similarity Score: 1.0\n",
      "Found the way you love me faith hill\n",
      "Similarity Score: 1.0\n",
      "Found never be the same ulrich schnauss\n",
      "Similarity Score: 1.0\n",
      "Found 3 birds the dead weather\n",
      "Similarity Score: 1.0\n",
      "Found amapola james last\n",
      "Similarity Score: 1.0\n",
      "Found towers little mix\n",
      "Similarity Score: 1.0\n",
      "Found isaiah boar\n",
      "Similarity Score: 1.0\n",
      "Found kosmos yob\n",
      "Similarity Score: 1.0\n",
      "Found pretty noose soundgarden\n",
      "Similarity Score: 1.0\n",
      "Found volare gipsy kings\n",
      "Similarity Score: 1.0\n",
      "Found where do you sleep at night lynch mob\n",
      "Similarity Score: 1.0\n",
      "Found the state of madness madness of the night\n",
      "Similarity Score: 1.0\n",
      "Found tower zola jesus\n",
      "Similarity Score: 1.0\n",
      "Found soul of fire witch\n",
      "Similarity Score: 1.0\n",
      "Found say you, say me lionel richie\n",
      "Similarity Score: 0.9824561403508771\n",
      "Found ...baby one more time britney spears\n",
      "Similarity Score: 0.9565217391304348\n",
      "Found in the air tonight phil collins\n",
      "Similarity Score: 1.0\n",
      "Found bela lugosi's dead bauhaus\n",
      "Similarity Score: 0.9803921568627451\n",
      "Found we're taking this kylesa\n",
      "Similarity Score: 0.9787234042553191\n",
      "Found eternal life jeff buckley\n",
      "Similarity Score: 1.0\n",
      "Found don diablo miguel bosé\n",
      "Similarity Score: 1.0\n",
      "Found dancing girl terry callier\n",
      "Similarity Score: 1.0\n",
      "Found bleed it dry alter bridge\n",
      "Similarity Score: 1.0\n",
      "Found take care michael henderson\n",
      "Similarity Score: 1.0\n",
      "Found sunshine of your love cream\n",
      "Similarity Score: 1.0\n",
      "Found is she secretly on my side? unwoman\n",
      "Similarity Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "final_result = dict()\n",
    "#Get Spotify's song duration\n",
    "track_list = db.cultural_tweet.distinct(\"track_id\")\n",
    "for track in track_list:\n",
    "    song_name = db.cultural_tweet.find_one({\"track_id\": track }, {\"track_title\" : 1 , \"artist_name\": 1})\n",
    "    search_query = song_name[\"track_title\"].lower() + \" \" + song_name[\"artist_name\"].lower()\n",
    "    search_result = sp.search(q = search_query, limit= 3, type=\"track\")\n",
    "    for t in search_result[\"tracks\"][\"items\"]:\n",
    "        artists = \" \".join(list(map(lambda x: x[\"name\"],t[\"artists\"])))\n",
    "        result_matcher = t[\"name\"].lower() + \" \" + artists.lower()\n",
    "        similarity_score = similar(search_query,result_matcher)\n",
    "        if(similarity_score > 0.95):\n",
    "            print(\"Found \" + result_matcher)\n",
    "            print(\"Similarity Score: \" + str(similarity_score))\n",
    "            final_result[track] = t[\"duration_ms\"]\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-cf8fe3713add>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     db.cultural_tweet.update_many({\"track_id\": track},\n\u001b[1;32m      3\u001b[0m                             {\"$set\" : {\n\u001b[0;32m----> 4\u001b[0;31m                                 \u001b[0;34m\"duration_ms\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mfinal_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m                             }})\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/roblescoulter/anaconda/lib/python3.5/site-packages/pymongo/collection.py\u001b[0m in \u001b[0;36mupdate_many\u001b[0;34m(self, filter, update, upsert, bypass_document_validation, collation)\u001b[0m\n\u001b[1;32m    949\u001b[0m                                   \u001b[0mcheck_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m                                   \u001b[0mbypass_doc_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbypass_document_validation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 951\u001b[0;31m                                   collation=collation)\n\u001b[0m\u001b[1;32m    952\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mUpdateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_concern\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macknowledged\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/roblescoulter/anaconda/lib/python3.5/site-packages/pymongo/collection.py\u001b[0m in \u001b[0;36m_update\u001b[0;34m(self, sock_info, criteria, document, upsert, check_keys, multi, manipulate, write_concern, op_id, ordered, bypass_doc_val, collation)\u001b[0m\n\u001b[1;32m    751\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__database\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m                 \u001b[0mcommand\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 753\u001b[0;31m                 codec_options=self.__write_response_codec_options).copy()\n\u001b[0m\u001b[1;32m    754\u001b[0m             \u001b[0m_check_write_command_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m             \u001b[0;31m# Add the updatedExisting field for compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/roblescoulter/anaconda/lib/python3.5/site-packages/pymongo/pool.py\u001b[0m in \u001b[0;36mcommand\u001b[0;34m(self, dbname, spec, slave_ok, read_preference, codec_options, check, allowable_errors, check_keys, read_concern, write_concern, parse_write_concern_error, collation)\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;31m# Catch socket.error, KeyboardInterrupt, etc. and close ourselves.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_connection_failure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_doc_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/roblescoulter/anaconda/lib/python3.5/site-packages/pymongo/pool.py\u001b[0m in \u001b[0;36m_raise_connection_failure\u001b[0;34m(self, error)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0m_raise_connection_failure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__eq__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/roblescoulter/anaconda/lib/python3.5/site-packages/pymongo/pool.py\u001b[0m in \u001b[0;36mcommand\u001b[0;34m(self, dbname, spec, slave_ok, read_preference, codec_options, check, allowable_errors, check_keys, read_concern, write_concern, parse_write_concern_error, collation)\u001b[0m\n\u001b[1;32m    417\u001b[0m                            \u001b[0mread_concern\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m                            \u001b[0mparse_write_concern_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_write_concern_error\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m                            collation=collation)\n\u001b[0m\u001b[1;32m    420\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOperationFailure\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/roblescoulter/anaconda/lib/python3.5/site-packages/pymongo/network.py\u001b[0m in \u001b[0;36mcommand\u001b[0;34m(sock, dbname, spec, slave_ok, is_mongos, read_preference, codec_options, check, allowable_errors, address, check_keys, listeners, max_bson_size, read_concern, parse_write_concern_error, collation)\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msendall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreceive_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m         unpacked = helpers._unpack_response(\n\u001b[1;32m    110\u001b[0m             response, codec_options=codec_options)\n",
      "\u001b[0;32m/Users/roblescoulter/anaconda/lib/python3.5/site-packages/pymongo/network.py\u001b[0m in \u001b[0;36mreceive_message\u001b[0;34m(sock, operation, request_id, max_message_size)\u001b[0m\n\u001b[1;32m    135\u001b[0m         sock, operation, request_id, max_message_size=MAX_MESSAGE_SIZE):\n\u001b[1;32m    136\u001b[0m     \u001b[0;34m\"\"\"Receive a raw BSON message or raise socket.error.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_receive_data_on_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m     \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_UNPACK_INT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/roblescoulter/anaconda/lib/python3.5/site-packages/pymongo/network.py\u001b[0m in \u001b[0;36m_receive_data_on_socket\u001b[0;34m(sock, length)\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mIOError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0m_errno_from_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0merrno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEINTR\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for track in final_result:\n",
    "    db.cultural_tweet.update_many({\"track_id\": track},\n",
    "                            {\"$set\" : {\n",
    "                                \"duration_ms\" : final_result[track]\n",
    "                            }})\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': ObjectId('59bfff98ed415cd14d0d27ea'),\n",
       " 'artist_id': '029796844c2ca8bc9380dc0a046a6223',\n",
       " 'artist_name': 'James Last',\n",
       " 'coordinates': None,\n",
       " 'created_at': '2014-03-04 11:22:52',\n",
       " 'duration_ms': 182693,\n",
       " 'geo': None,\n",
       " 'hashtags': ['radionomy'],\n",
       " 'id': 440794499095478300,\n",
       " 'place': None,\n",
       " 'source': 'Share.Radionomy.com',\n",
       " 'text': '#NowPLaying James Last - Amapola http://t.co/ucxjELVE5a #ListenLive #radionomy #Instrumental',\n",
       " 'track_id': '0669adeb25a376ad2219737816de38cf',\n",
       " 'track_title': 'Amapola',\n",
       " 'tweet_lang': 'sk',\n",
       " 'user_id': 'a4efac8193cba040f6019100343944a59d837f1',\n",
       " 'user_lang': 'nl',\n",
       " 'user_location': '',\n",
       " 'user_time_zone': None}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-11-8ae5e2d82f58>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-11-8ae5e2d82f58>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    Analyze the music listening behavior of people on Twitter and analyze the emotion in tweets they posted while listening to this music\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Analyze the music listening behavior of people on Twitter and analyze the emotion in tweets \n",
    "they posted while listening to this music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
